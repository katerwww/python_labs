# __–õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 1__
## –∑–∞–¥–∞–Ω–∏–µ 1
```
a = input()
b = int(input())
c = b + 1
print(f"–ü—Ä–∏–≤–µ—Ç, {a}! –ß–µ—Ä–µ–∑ –≥–æ–¥ —Ç–µ–±–µ –±—É–¥–µ—Ç {c}.")
```
![01](./images/lab01/lab01_ex01.png)
## –∑–∞–¥–∞–Ω–∏–µ 2
```
a = float(input())
b = float(input())
summ = a + b
avg = round((a + b)/2, 2)
print(f"sum={summ}; avg={avg}")
```
![02](./images/lab01/lab01_ex02.png)
## –∑–∞–¥–∞–Ω–∏–µ 3
```
price = float(input())
discount = float(input())
vat = float(input())

base = round(price * (1 - discount/100), 2)
vat_amount = round(base * (vat/100), 2)
total = round(base + vat_amount, 2)

print(f"–ë–∞–∑–∞ –ø–æ—Å–ª–µ —Å–∫–∏–¥–∫–∏: {base} ‚ÇΩ")
print(f"–ù–î–°: {vat_amount} ‚ÇΩ")
print(f"–ò—Ç–æ–≥–æ –∫ –æ–ø–ª–∞—Ç–µ: {total} ‚ÇΩ")
```
![03](./images/lab01/lab01_ex03.png)
## –∑–∞–¥–∞–Ω–∏–µ 4
```
min = int(input())
hours = min//60
ost_min = min%60
print(f"{hours} : {ost_min:02d}")
```
![04](./images/lab01/lab01_ex04.png)
## –∑–∞–¥–∞–Ω–∏–µ 5
```
name = input().strip()
nam = name.split()
m = len(''.join(nam))+2
n = []
for i in nam:
    a = i[0]
    n.append(a)
h = ''.join(n)
print(f"–ò–Ω–∏—Ü–∏–∞–ª—ã: {h}.")
print(f"–î–ª–∏–Ω–∞ (—Å–∏–º–≤–æ–ª–æ–≤): {m}")
```
![05](./images/lab01/lab01_ex05.png)


# __–õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 2__
## –∑–∞–¥–∞–Ω–∏–µ 1 
```
def min_max(nums: list[float | int]) -> tuple[float | int, float | int]:
    if not nums:
        return ValueError
    return (min(nums), max(nums))
print(min_max([3, -1, 5, 5, 0]))
print(min_max([42]))
print(min_max([-5, -2, -9]))
print(min_max([ ]))
print(min_max([1.5, 2, 2.0, -3.1]))

def unique_sorted(nums: list[float | int]) -> list[float | int]:
    return sorted(set(nums))
print(unique_sorted([3, 1, 2, 1, 3]))
print(unique_sorted([]))
print(unique_sorted([-1, -1, 0, 2, 2]))
print(unique_sorted([1.0, 1, 2.5, 2.5, 0]))

def flatten(mat: list[list | tuple]) -> list:
    res = []
    for x in mat:
        if not isinstance(x, (list, tuple)):
            return ValueError
        res.extend(x)
    return res

print(flatten([[1, 2], [3, 4]]))
print(flatten([[1, 2], (3, 4, 5)]))
print(flatten([[1], [], [2, 3]]))
print(flatten([[1, 2], "ab"]))
```
![01](./images/lab02/lab02_ex01.png)

## –∑–∞–¥–∞–Ω–∏–µ 2 
```
def transpose(mat: list[list[float | int]]) -> list[list]:
    if not mat:
        return []
    rv_l = len(mat[0])
    for rv in mat:
        if len(rv) != rv_l:
            return ValueError
    return [[mat[j][i] for j in range(len(mat))] for i in range(rv_l)]

print(transpose([[1, 2, 3]]))
print(transpose([[1], [2], [3]]))
print(transpose([[1, 2], [3, 4]]))
print(transpose([]))
print(transpose([[1, 2], [3]]))

def row_sums(mat: list[list[float | int]]) -> list[float]:
    if not mat:
        return []
    
    row_length = len(mat[0])
    for row in mat:
        if len(row) != row_length:
            return ValueError
    
    return [sum(row) for row in mat]
print(row_sums([[1, 2, 3], [4, 5, 6]]))
print(row_sums([[-1, 1], [10, -10]]))
print(row_sums([[0, 0], [0, 0]]))
print(row_sums([[1, 2], [3]]))

def col_sums(mat: list[list[float | int]]) -> list[float]:
    if not mat:
        return []
    
    row_length = len(mat[0])
    for row in mat:
        if len(row) != row_length:
            return ValueError
    
    return [sum(mat[i][j] for i in range(len(mat))) for j in range(row_length)]

print(col_sums([[1, 2, 3], [4, 5, 6]]))
print(col_sums([[-1, 1], [10, -10]]))
print(col_sums([[0, 0], [0, 0]]))
print(col_sums([[1, 2], [3]]))
```
![02](./images/lab02/lab02_ex02.png)

## –∑–∞–¥–∞–Ω–∏–µ 3 
```
def format_record(rec:tuple[str,str,float])-> str:
    fio,group,gpa=rec
    part_fio=[part.strip() for part in fio.split() if part.strip()]
    ini=[]
    for part in part_fio[1:]:
        if part:
            ini.append(f"{part[0].upper()}.")
    res_fio=f"{part_fio[0]} {''.join(ini)}"
    res_gpa=f"{gpa:.2f}"
    return f"{res_fio}, –≥—Ä. {group}, GPA {res_gpa}"
print(format_record(("–ò–≤–∞–Ω–æ–≤ –ò–≤–∞–Ω –ò–≤–∞–Ω–æ–≤–∏—á", "BIVT-25", 4.6) ))
print(format_record(("–ü–µ—Ç—Ä–æ–≤ –ü—ë—Ç—Ä", "IKBO-12", 5.0)))
print(format_record(("–ü–µ—Ç—Ä–æ–≤ –ü—ë—Ç—Ä –ü–µ—Ç—Ä–æ–≤–∏—á", "IKBO-12", 5.0)))
print(format_record(("  —Å–∏–¥–æ—Ä–æ–≤–∞  –∞–Ω–Ω–∞   —Å–µ—Ä–≥–µ–µ–≤–Ω–∞ ", "ABB-01", 3.999)))

```
![03](./images/lab02/lab02_ex03.png)

# __–õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 3__
## normalize
```
def normalize(text: str, *, casefold: bool = True, yo2e: bool = True) -> str:
    text = text.casefold() 
    if yo2e:
        text = text.replace('—ë', '–µ').replace('–Å', '–ï')
    text = text.replace('\t', ' ').replace('\r', ' ').replace('\n', ' ')
    text = " ".join(text.split()) 
    text = text.strip() 
    return text

print(normalize("–ü—Ä–ò–≤–ï—Ç\n–ú–ò—Ä\t")) 
print(normalize("—ë–∂–∏–∫, –Å–ª–∫–∞"))
print(normalize("Hello\r\nWorld"))
print(normalize("  –¥–≤–æ–π–Ω—ã–µ   –ø—Ä–æ–±–µ–ª—ã  "))
```
![01](./images/lab03/lab03_nor.png)

## tokenize
```
import re
def tokenize(text: str) -> list[str]:
    return re.findall(r'\w+(?:-\w+)*', text)  

print(tokenize("–ø—Ä–∏–≤–µ—Ç –º–∏—Ä"))
print(tokenize("hello,world!!!"))
print(tokenize("–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É –∫—Ä—É—Ç–æ"))
print(tokenize("2025 –≥–æ–¥"))
print(tokenize("emoji üòÄ –Ω–µ —Å–ª–æ–≤–æ"))

```
![02](./images/lab03/lab03_tok.png)

## count_freq + top_n
``` 
def count_freq(tokens: list[str]) -> dict[str, int]:
    c = {}  
    for w in tokens:
        cu = c.get(w, 0) 
        c[w] = cu + 1
    return c
def top_n(freq: dict[str, int], n: int = 5) -> list[tuple[str, int]]:
    t = []
    for w, count in freq.items():
        t.append((-count, w))
    t.sort()
    result = []
    for neg_count, w in t:
        result.append((w, -neg_count))
    return result[:n]
tok = ["a", "b", "a", "c", "b", "a"]
freq = count_freq(tok)
print(top_n(freq, n=2))
tok_2 = ["bb", "aa", "bb", "aa", "cc"]
freq_2 = count_freq(tok_2)
print(top_n(freq_2, n=2))

```
![03](./images/lab03/lab03_cou+top.png)

## text_stats
``` 
import sys
import re
from lib.text import normalize, tokenize, count_freq, top_n

a = str(input())
n =normalize(a) 
allwords = tokenize(n) 
uw = count_freq(allwords) 
top = top_n(uw,5) 
print(f'–í—Å–µ–≥–æ —Å–ª–æ–≤: {len(allwords)}') 
print(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: {len(uw)}")
print("–¢–æ–ø-5:")
for y in top:
    print(y[0] + ': ' + str(y[1]))

```
![04](./images/lab03/lab03_text_stats.png)

# __–õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 4__
## –ó–∞–¥–∞–Ω–∏–µ A ‚Äî –º–æ–¥—É–ª—å src/lab04/io_txt_csv.py
```
import csv
from pathlib import Path
from typing import Iterable, Sequence

def read_text(path: str | Path, encoding: str = "utf-8") -> str:
    try:
        return Path(path).read_text(encoding=encoding)
    except FileNotFoundError:
        return "–¢–∞–∫–æ–≥–æ —Ñ–∞–π–ª–∞ –Ω–µ—Ç—É"
    except UnicodeDecodeError:
        return "–ù–µ—É–¥–∞–ª–æ—Å—å –∏–∑–º–µ–Ω–∏—Ç—å –∫–æ–¥–∏—Ä–æ–≤–∫—É"

def write_csv(rows: list[tuple | list], path: str | Path, header: tuple[str, ...] | None = None) -> None:
    p = Path(path)
    with p.open('w', newline="", encoding="utf-8") as file: # –∫–æ–Ω—Ç—Ä–æ–ª—å –ø–µ—Ä–µ–Ω–æ—Å–∞ —Å—Ç—Ä–æ–∫,–∫–æ–¥–∏—Ä–æ–≤–≤–∫–∞ —Ñ–∞–π–ª–∞
        f = csv.writer(file)
        if header is None and rows == []: # –Ω–µ—Ç –∑–∞–≥–æ–ª–æ–≤–∫–∞ –∏ –¥–∞–Ω–Ω—ã—Ö
            file_c.writerow(('a', 'b')) 
        if header is not None:
            f.writerow(header)
        if rows != []:
            const = len(rows[0])
            for i in rows:
                if len(i) != const:
                    return ValueError
        f.writerows(rows)

def ensure_parent_dir(path: str | Path) -> None:
    Path(path).parent.mkdir(parents=True, exist_ok=True)

print(read_text(r"C:\Users\lezgi\Desktop\python_labs\data\lab04\input.txt"))
write_csv([("word","count"),("test",3)], r"C:\Users\lezgi\Desktop\python_labs\data\lab04\check.csv") 

```
![01](./images/lab04/lab04_ex01.png)

## –ó–∞–¥–∞–Ω–∏–µ B ‚Äî —Å–∫—Ä–∏–ø—Ç src/lab04/text_report.py
```
from io_txt_csv import read_text, write_csv, ensure_parent_dir
import sys
from pathlib import Path

sys.path.append(r'C:\Users\Home\Documents\GitHub\lab_01\lib')

from lib.text import normalize, tokenize, count_freq, top_n


def exist_path(path_f: str):
    return Path(path_f).exists() #—Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —Ñ–∞–π–ª 


def main(file: str, encoding: str = 'utf-8'): 
    if not exist_path(file):
        raise FileNotFoundError 
    
    file_path = Path(file)
    text = read_text(file, encoding=encoding) # —Ç–µ–∫—Å—Ç –≤ –æ–¥–Ω—É —Å—Ç—Ä–æ–∫—É
    norm = normalize(text) 
    tokens = tokenize(norm)
    freq_dict = count_freq(tokens)
    top = top_n(freq_dict, 5)
    top_sort = sorted(top, key=lambda x: (x[1], x[0]), reverse=True) # —Å–æ—Ä—Ç–∏—Ä—É–µ—Ç —Å–ø–∏—Å–æ–∫, –∫—Ä–∏—Ç–µ—Ä–∏–∏ —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏, —á–∞—Å—Ç–æ—Ç–∞ —Å–ª–æ–≤–æ –∏ —Å–∞–º–æ —Å–ª–æ–≤–æ, —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ —É–±—ã–≤–∞–Ω–∏—é
    report_path = file_path.parent / 'report.csv' # c–æ–∑–¥–∞–µ—Ç –ø—É—Ç—å –¥–ª—è —Ñ–∞–π–ª–∞ –æ—Ç—á–µ—Ç–∞ –≤ —Ç–æ–π –∂–µ –ø–∞–ø–∫–µ, –≥–¥–µ –∏—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª
    write_csv(top_sort, report_path, header=('word', 'count'))
    
    print(f'–í—Å–µ–≥–æ —Å–ª–æ–≤: {len(tokens)}')
    print(f'–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: {len(freq_dict)}')
    print('–¢–æ–ø-5:')
    for cursor in top_sort:
        print(f'{cursor[0]}: {cursor[-1]}')


main(r'C:\Users\lezgi\Desktop\python_labs\data\lab04\input.txt')

```
![02](./images/lab04/lab04_ex02.png)
![03](./images/lab04/lab04_ex02csv.png)

# ___–õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 5___
## –ó–∞–¥–∞–Ω–∏–µ A ‚Äî JSON ‚Üî CSV
``` 
import csv, json, sys, os
from pathlib import Path
def is_valid_json_file(file_path: str) -> bool:
    try:
        if not os.path.exists(file_path) or os.path.getsize(file_path) == 0:
            return False
        
        with open(file_path, 'r', encoding='utf-8') as file:
            json_data = json.load(file) #p–∞–≥—Ä—É–∂–∞–µ—Ç JSON –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ñ–∞–π–ª–∞.
            return isinstance(json_data, list) and len(json_data) > 0 and all(isinstance(item, dict) for item in json_data) # —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å–ø–∏—Å–∫–æ–º, —Å–ø–∏—Å–æ–∫ –Ω–µ –ø—É—Å—Ç–æ–π, –≤—Å–µ —ç–ª–µ–º–µ–Ω—Ç—ã —Å–ø–∏—Å–∫–∞ —è–≤–ª—è—é—Ç—Å—è —Å–ª–æ–≤–∞—Ä—è–º–∏
    except:
        return False

def is_valid_csv_file(file_path: str) -> bool:
    try:
        if not os.path.exists(file_path) or os.path.getsize(file_path) == 0:
            return False
            
        with open(file_path, 'r', encoding='utf-8') as file:
            reader = csv.reader(file)  
            header = next(reader, None) #—á–∏—Ç–∞–µ—Ç CSV —Ñ–∞–π–ª –∏ –ø–æ–ª—É—á–∞–µ—Ç –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É
            return header is not None and len(header) > 0
    except:
        return False

def json_to_csv(json_path: str, csv_path: str) -> None:
    if not is_valid_json_file(json_path): # JSON —Ñ–∞–π–ª –Ω–µ —Å–æ–æ—Ç–≤–µ—Å—Ç–≤—É–µ—Ç –∫—Ä–∏—Ç–µ—Ä–∏—è–º, –≤—ã–≤–æ–¥–∏—Ç –æ—à–∏–±–∫—É –∏ –∑–∞–≤–µ—Ä—à–∏—Ç –ø—Ä–æ–≥—Ä–∞–º–º—É
        print("ValueError: Input file is not a valid JSON or is empty")
        sys.exit(1) 
    json_path=Path(json_path)
    csv_path=Path(csv_path)
    if json_path.suffix.lower() != ".json": #–ø—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è —Ñ–∞–π–ª–æ–≤, lower-–º–µ—Ç–æ–¥ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –≤ –Ω–∏–∂–Ω–∏–π —Ä–µ–≥–∏—Å—Ç—Ä
        raise ValueError(f"–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –≤—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞: –æ–∂–∏–¥–∞–µ—Ç—Å—è .json")
    if csv_path.suffix.lower() != ".csv":  #–ø—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è —Ñ–∞–π–ª–æ–≤
        raise ValueError(f"–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞: –æ–∂–∏–¥–∞–µ—Ç—Å—è .csv")
    

    with open(json_path, 'r', encoding='utf-8') as json_file:
        json_data = json.load(json_file) 

    with open(csv_path, 'w', newline='', encoding='utf-8') as csvfile:
        writer = csv.DictWriter(csvfile, fieldnames=json_data[0].keys()) #—Å–æ–∑–¥–∞–µ—Ç CSV —Ñ–∞–π–ª —Å –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏ –∏–∑ –∫–ª—é—á–µ–π –ø–µ—Ä–≤–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞ JSON, –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫ = –∫–ª—é—á–∏ –ø–µ—Ä–≤–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞
        writer.writeheader()  
        writer.writerows(json_data) 

def csv_to_json(csv_path: str, json_path: str) -> None:
    if not is_valid_csv_file(csv_path):
        print("ValueError: Input file is not a valid CSV or is empty")
        sys.exit(1)
    json_path=Path(json_path)
    csv_path=Path(csv_path)
    if json_path.suffix.lower() != ".json":
        raise ValueError(f"–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞: –æ–∂–∏–¥–∞–µ—Ç—Å—è .json")
    if csv_path.suffix.lower() != ".csv":
        raise ValueError(f"–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –≤—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞: –æ–∂–∏–¥–∞–µ—Ç—Å—è .csv")

    with open(csv_path, 'r', encoding='utf-8') as csvfile:
        reader = csv.DictReader(csvfile)  #—á–∏—Ç–∞–µ—Ç CSV –∫–∞–∫ —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π
        data = list(reader) 
    
    with open(json_path, 'w', encoding='utf-8') as jsonfile:
        json.dump(data, jsonfile, ensure_ascii=False, indent=4) 
csv_to_json(r"C:\Users\lezgi\Desktop\python_labs\data\samples\people.csv",r"C:\Users\lezgi\Desktop\python_labs\data\out\people_from_json.json")

json_to_csv( r"C:\Users\lezgi\Desktop\python_labs\data\samples\people.json",  r"C:\Users\lezgi\Desktop\python_labs\data\out\people_from_csv.csv" )
```
![01](./images/lab05/a_out_csv.png)
![02](./images/lab05/a_out_json.png)
![03](./images/lab05/a_sam_csv.png)
![04](./images/lab05/a_sam_json.png)

## –ó–∞–¥–∞–Ω–∏–µ B ‚Äî CSV ‚Üí XLSX
``` 
import os
import csv
import sys
from pathlib import Path
from openpyxl import Workbook 

def csv_to_xlsx(csv_path: str, xlsx_path: str) -> None: 
    if not os.path.exists(csv_path):  
        print("FileNotFoundError") 
        sys.exit(1) #–∑–∞–≤–µ—Ä—à–∞–µ—Ç –ø—Ä–æ–≥—Ä–∞–º–º—É —Å –æ—à–∏–±–∫–æ–π 1
    xlsx_path=Path(xlsx_path)
    csv_path=Path(csv_path)
    if xlsx_path.suffix.lower() != ".xlsx": #–ø–æ–ª—É—á–∞–µ—Ç —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ñ–∞–π–ª–∞,–ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –≤ –Ω–∏–∂–Ω–∏–π —Ä–µ–≥–∏—Å—Ç—Ä
        raise ValueError(f"–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞: –æ–∂–∏–¥–∞–µ—Ç—Å—è .xlsx")
    if csv_path.suffix.lower() != ".csv":
        raise ValueError(f"–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –≤—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞: –æ–∂–∏–¥–∞–µ—Ç—Å—è .csv")

    if os.path.getsize(csv_path) == 0: #–ø–æ–ª—É—á–∞–µ—Ç —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ –≤ –±–∞–π—Ç–∞—Ö
        print("ValueError")
        sys.exit(1)
    wb = Workbook() # c
    ws = wb.active  #–ø–æ–ª—É—á–∞–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã–π –ª–∏—Å—Ç
    ws.title = "Sheet1" #—É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ –ª–∏—Å—Ç–∞ "Sheet1"

    with open(csv_path, "r", encoding="utf-8") as csv_file: 
        reader = csv.reader(csv_file) # —Å–æ–∑–¥–∞–µ—Ç –æ–±—ä–µ–∫—Ç –¥–ª—è —á—Ç–µ–Ω–∏—è CSV –ø–æ—Å—Ç—Ä–æ—á–Ω–æ
        for row in reader: 
            ws.append(row) 
    for column_cells in ws.columns: 
        max_length = 0 
        column_letter = column_cells[0].column_letter #–ø–æ–ª—É—á–∞–µ—Ç –±—É–∫–≤—É –∫–æ–ª–æ–Ω–∫–∏
        for cell in column_cells: 
            if cell.value: 
                max_length = max(max_length, len(str(cell.value))) 
        ws.column_dimensions[column_letter].width = max(max_length + 2, 8) #–æ–±—Ä–∞—â–∞–µ—Ç—Å—è –∫ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º —à–∏—Ä–∏–Ω—ã –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –∫–æ–ª–æ–Ω–∫–∏, —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç —à–∏—Ä–∏–Ω—É –∫–æ–ª–æ–Ω–∫–∏, –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ + 2 —Å–∏–º–≤–æ–ª–∞ –¥–ª—è –æ—Ç—Å—Ç—É–ø–∞, 8- –≤—ã–±–∏—Ä–∞–µ—Ç –±–æ–ª—å—à–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –º–µ–∂–¥—É —Ä–∞—Å—á–∏—Ç–∞–Ω–Ω–æ–π —à–∏—Ä–∏–Ω–æ–π –∏ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π —à–∏—Ä–∏–Ω–æ–π 8 
    wb.save(xlsx_path)
csv_to_xlsx(r"C:\Users\Home\lab_python\lab_python-2\data\samples\cities.csv", r"C:\Users\Home\lab_python\lab_python-2\data\out\people.xlsx")    
```
![01](./images/lab05/b_sam.png)
![02](./images/lab05/b_out.png)

# ___–õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 6___
## –ó–∞–¥–∞–Ω–∏–µ A
```
import argparse
from pathlib import Path
from lib.text import tokenize, count_freq, top_n

def main():
    
    # —Å–æ–∑–¥–∞–Ω–∏–µ –æ–±—ä–µ–∫—Ç–∞ –ø–∞—Ä—Å–µ—Ä–∞ —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º –ø—Ä–æ–≥—Ä–∞–º–º—ã
    parser = argparse.ArgumentParser(description="CLI-—É—Ç–∏–ª–∏—Ç—ã –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–æ–π ‚Ññ6")

   
    subparsers = parser.add_subparsers(dest="command", help="–î–æ—Å—Ç—É–ø–Ω—ã–µ —Å–æ–º–∞–Ω–¥—ã")

    stats_parser = subparsers.add_parser("stats", help="–ß–∞—Å—Ç–æ—Ç—ã —Å–ª–æ–≤ –≤ —Ç–µ–∫—Å—Ç–µ")
    stats_parser.add_argument("--input", required=True, help="–í—Ö–æ–¥–Ω–æ–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª")
    stats_parser.add_argument("--top", type=int, default=5, help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–ø–æ–≤—ã—Ö —Å–ª–æ–≤ "
    "(–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 5)")
    cat_parser = subparsers.add_parser("cat", help="–í—ã–≤–æ–¥ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —Ñ–∞–π–ª–∞")
    cat_parser.add_argument("--input", required=True, help="–ü—É—Ç—å –∫ –≤—Ö–æ–¥–Ω–æ–º—É —Ñ–∞–π–ª—É")
    cat_parser.add_argument("-n", action="store_true", help="–ù—É–º–µ—Ä–æ–≤–∞—Ç—å —Å—Ç—Ä–æ–∫–∏")

    args = parser.parse_args()

    file = Path(args.input) # —Å–æ–∑–¥–∞–Ω–∏–µ –æ–±—ä–µ–∫—Ç–∞ Path –∏–∑ –ø–µ—Ä–µ–¥–∞–Ω–Ω–æ–≥–æ –ø—É—Ç–∏ –∫ —Ñ–∞–π–ª—É

    if not file.exists():
        parser.error("–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω")
    
    if args.command == "cat": # —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–∞–Ω–¥—ã cat
        with open(file, "r", encoding="utf-8") as f:
            number = 1
            for row in f:
                row = row.rstrip("\n") 
                if args.n: # –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω —Ñ–ª–∞–≥ n -> –ø–µ—á–∞—Ç–∞–µ–º –ø—Ä–æ–Ω—É–º–µ—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏, –µ—Å–ª–∏ –Ω–µ—Ç, –ø—Ä–æ—Å—Ç–æ —Å—Ç—Ä–æ–∫–∏
                    print(f"{number}: {row}")
                    number += 1
                else:
                    print(row)

    elif args.command == "stats": # —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–∞–Ω–¥—ã stats
        with open(file, "r", encoding="utf-8") as f:
            data = [row for row in f]
        data = "".join(data)
        tokens = tokenize(text=data)
        freq = count_freq(tokens=tokens)
        top = top_n(freq=freq, n=args.top)

        # –≤—ã–≤–æ–¥–∏–º —Ç–æ–ø —Å–ª–æ–≤
        number = 1
        for x, y in top:
            print(f"{number}. {x} - {y}")
            number += 1

if __name__ == "__main__":
    main()

```
![01](./images/lab06/lab06_a1.png)
![02](./images/lab06/lab06_n.png)
![03](./images/lab06/lab06_top.png)
![04](./images/lab06/lab06_h.png)

## –ó–∞–¥–∞–Ω–∏–µ B
```

import argparse
from pathlib import Path
from lib.json_csv import json_to_csv, csv_to_json
from lib.csv_xlsx import csv_to_xlsx  

def main():
    parser = argparse.ArgumentParser(description="–ö–æ–Ω–≤–µ—Ä—Ç–µ—Ä –¥–∞–Ω–Ω—ã—Ö –º–µ–∂–¥—É —Ñ–æ—Ä–º–∞—Ç–∞–º–∏")
    subparsers = parser.add_subparsers(dest="command", help="–î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏")

    # JSON ‚Üí CSV
    json_to_csv_parser = subparsers.add_parser("json_to_csv", help="–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å JSON –≤ CSV")
    json_to_csv_parser.add_argument("--in", dest="input", required=True, help="–í—Ö–æ–¥–Ω–æ–π JSON —Ñ–∞–π–ª")
    json_to_csv_parser.add_argument("--out", dest="output", required=True, help="–í—ã—Ö–æ–¥–Ω–æ–π CSV —Ñ–∞–π–ª")

    # CSV ‚Üí JSON
    csv_to_json_parser = subparsers.add_parser("csv_to_json", help="–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å CSV –≤ JSON")
    csv_to_json_parser.add_argument("--in", dest="input", required=True, help="–í—Ö–æ–¥–Ω–æ–π CSV —Ñ–∞–π–ª")
    csv_to_json_parser.add_argument("--out", dest="output", required=True, help="–í—ã—Ö–æ–¥–Ω–æ–π JSON —Ñ–∞–π–ª")

    # CSV ‚Üí XLSX
    csv_to_xlsx_parser = subparsers.add_parser("csv_to_xlsx", help="–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å CSV –≤ XLSX")
    csv_to_xlsx_parser.add_argument("--in", dest="input", required=True, help="–í—Ö–æ–¥–Ω–æ–π CSV —Ñ–∞–π–ª")
    csv_to_xlsx_parser.add_argument("--out", dest="output", required=True, help="–í—ã—Ö–æ–¥–Ω–æ–π XLSX —Ñ–∞–π–ª")

    args = parser.parse_args()

    if args.command == "json_to_csv":
        json_to_csv(json_path=args.input, csv_path=args.output)

    elif args.command == "csv_to_json":
        csv_to_json(csv_path=args.input, json_path=args.output)

    elif args.command == "csv_to_xlsx":
        csv_to_xlsx(csv_path=args.input, xlsx_path=args.output)

if __name__ == "__main__":
    main()

```
![05](./images/lab06/lab06_json.png)
![06](./images/lab06/lab06_csv_js.png)

# ___–õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 7___
## –ó–∞–¥–∞–Ω–∏–µ text.py
```
import pytest
import sys
import os

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –ø—Ä–æ–µ–∫—Ç–∞ –≤ –ø—É—Ç—å
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, project_root)

from src.lib.text import normalize, tokenize, count_freq, top_n


@pytest.mark.parametrize(
    "source, expected",
    [
        ("–ü—Ä–ò–≤–ï—Ç\n–ú–ò—Ä\t", "–ø—Ä–∏–≤–µ—Ç –º–∏—Ä"),
        ("—ë–∂–∏–∫, –Å–ª–∫–∞", "–µ–∂–∏–∫, –µ–ª–∫–∞"),
        ("Hello\r\nWorld", "hello world"),
        ("  –¥–≤–æ–π–Ω—ã–µ   –ø—Ä–æ–±–µ–ª—ã  ", "–¥–≤–æ–π–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã"),
        ("", ""),
        ("   ", ""),
    ],
)
def test_normalize(source, expected):
    assert normalize(source) == expected


@pytest.mark.parametrize(
    "text, expected",
    [
        ("–ø—Ä–∏–≤–µ—Ç –º–∏—Ä", ["–ø—Ä–∏–≤–µ—Ç", "–º–∏—Ä"]),
        ("hello world test", ["hello", "world", "test"]),
        ("", []),
        ("   ", []),
        ("–∑–Ω–∞–∫–∏, –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è! —Ç–µ—Å—Ç.", ["–∑–Ω–∞–∫–∏", "–ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è", "—Ç–µ—Å—Ç"]),
    ],
)
def test_tokenize(text, expected):
    assert tokenize(text) == expected


def test_count_freq_basic():
    tokens = ["apple", "banana", "apple", "cherry", "banana", "apple"]
    result = count_freq(tokens)
    expected = {"apple": 3, "banana": 2, "cherry": 1}
    assert result == expected


def test_count_freq_empty():
    assert count_freq([]) == {}


def test_top_n_basic():
    freq = {"apple": 5, "banana": 3, "cherry": 7, "date": 1}
    result = top_n(freq, 2)
    expected = [("cherry", 7), ("apple", 5)]
    assert result == expected


def test_top_n_tie_breaker():
    freq = {"banana": 3, "apple": 3, "cherry": 3}
    result = top_n(freq, 3)
    expected = [("apple", 3), ("banana", 3), ("cherry", 3)]
    assert result == expected


def test_top_n_empty():
    assert top_n({}, 5) == []


def test_full_pipeline():
    text = "–ü—Ä–∏–≤–µ—Ç –º–∏—Ä! –ü—Ä–∏–≤–µ—Ç –≤—Å–µ–º. –ú–∏—Ä –ø—Ä–µ–∫—Ä–∞—Å–µ–Ω."
    normalized = normalize(text)
    tokens = tokenize(normalized)
    freq = count_freq(tokens)
    top_words = top_n(freq, 2)

    assert normalized == "–ø—Ä–∏–≤–µ—Ç –º–∏—Ä! –ø—Ä–∏–≤–µ—Ç –≤—Å–µ–º. –º–∏—Ä –ø—Ä–µ–∫—Ä–∞—Å–µ–Ω."
    assert tokens == [
        "–ø—Ä–∏–≤–µ—Ç",
        "–º–∏—Ä",
        "–ø—Ä–∏–≤–µ—Ç",
        "–≤—Å–µ–º",
        "–º–∏—Ä",
        "–ø—Ä–µ–∫—Ä–∞—Å–µ–Ω",
    ]
    assert freq == {"–ø—Ä–∏–≤–µ—Ç": 2, "–º–∏—Ä": 2, "–≤—Å–µ–º": 1, "–ø—Ä–µ–∫—Ä–∞—Å–µ–Ω": 1}
    assert top_words == [("–º–∏—Ä", 2), ("–ø—Ä–∏–≤–µ—Ç", 2)]
```
![01](./images/lab07/tests.png)

## –ó–∞–¥–∞–Ω–∏–µ json_csv.py
```
import sys
import os

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
sys.path.insert(0, project_root)

import pytest
import csv
import json
from pathlib import Path
from src.lab05.json_csv import json_to_csv, csv_to_json


def test_json_to_csv_roundtrip(tmp_path: Path):
    src = tmp_path / "people.json"
    dst = tmp_path / "people.csv"
    data = [
        {"name": "Alice", "age": 22},
        {"name": "Bob", "age": 25},
    ]
    src.write_text(json.dumps(data, ensure_ascii=False, indent=2), encoding="utf-8")
    json_to_csv(str(src), str(dst))
    with dst.open(encoding="utf-8") as f:
        rows = list(csv.DictReader(f))
    assert len(rows) == 2
    assert {"name", "age"} <= set(rows[0].keys())


def test_csv_to_json_roundtrip(tmp_path: Path):
    src = tmp_path / "people.csv"
    dst = tmp_path / "people.json"
    data = [
        {"name": "Alice", "age": "22"},
        {"name": "Bob", "age": "25"},
    ]
    with open(src, "w", newline="", encoding="utf-8") as f:
        fieldnames = list(data[0].keys())
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()
        writer.writerows(data)
    csv_to_json(str(src), str(dst))
    with dst.open(encoding="utf-8") as f:
        rows = json.load(f)
    assert len(rows) == 2


@pytest.mark.parametrize(
    "function, input_file, error",
    [
        (json_to_csv, "people.json", ValueError),
    ],
)
def test_error_handling(function, input_file, error, tmp_path: Path):
    file_path = tmp_path / input_file
    file_path.write_text("Error???", encoding="utf-8")
    dst = tmp_path / "people.csv"
    f = json_to_csv if function is json_to_csv else csv_to_json
    with pytest.raises(error):
        f(str(file_path), str(dst))

```
![02](./images/lab07/json_csv.png)

## black
![03](./images/lab07/black.png)

# ___–õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 8___
## models.py
``` 
from dataclasses import dataclass
from datetime import datetime, date
import re

@dataclass
class Student:
    fio: str
    birthdate: str
    group: str
    gpa: float
    
    def __post_init__(self):
        if not re.match(r'^\d{4}-\d{2}-\d{2}$', self.birthdate):
            raise ValueError(f"–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–∞—Ç—ã: {self.birthdate}. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ñ–æ—Ä–º–∞—Ç YYYY-MM-DD")
        try:
            datetime.strptime(self.birthdate, "%Y-%m-%d")
        except ValueError:
            raise ValueError(f"–ù–µ–≤–µ—Ä–Ω–∞—è –¥–∞—Ç–∞: {self.birthdate}")
        if not (0 <= self.gpa <= 5):
            raise ValueError(f"–°—Ä–µ–¥–Ω–∏–π –±–∞–ª–ª –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ –æ—Ç 0 –¥–æ 5, –ø–æ–ª—É—á–µ–Ω–æ: {self.gpa}")
        if len(self.fio.split()) < 2:
            raise ValueError(f"–§–ò–û –¥–æ–ª–∂–Ω–æ —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∏–º—è –∏ —Ñ–∞–º–∏–ª–∏—é: {self.fio}")
    
    def age(self) -> int:
        birth_date = datetime.strptime(self.birthdate, "%Y-%m-%d").date()
        today = date.today()
        
        age = today.year - birth_date.year
        
        if (today.month, today.day) < (birth_date.month, birth_date.day):
            age -= 1
            
        return age
    
    def to_dict(self) -> dict:
        return {
            "fio": self.fio,
            "birthdate": self.birthdate,
            "group": self.group,
            "gpa": self.gpa
        }
    
    @classmethod
    def from_dict(cls, data: dict):
        return cls(
            fio=data.get("fio", ""),
            birthdate=data.get("birthdate", ""),
            group=data.get("group", ""),
            gpa=data.get("gpa", 0.0)
        )
    
    def __str__(self) -> str:
        return f"{self.fio}, –≥—Ä—É–ø–ø–∞: {self.group}, –≤–æ–∑—Ä–∞—Å—Ç: {self.age()}, —Å—Ä–µ–¥–Ω–∏–π –±–∞–ª–ª: {self.gpa}"


if __name__ == "__main__":
    try:
        student = Student(
            fio="–ò–≤–∞–Ω–æ–≤ –ò–≤–∞–Ω –ò–≤–∞–Ω–æ–≤–∏—á",
            birthdate="2007-10-06",
            group="–ë–ò–í–¢-25-1",
            gpa=3.5
        )
        print(student)
        print(f"–°–ª–æ–≤–∞—Ä—å: {student.to_dict()}")
    except ValueError as e:
        print(f"–û—à–∏–±–∫–∞: {e}")

```
![01](./images/lab08/models.png)

## serialize.p
``` 
import json
from typing import List
from models import Student
def students_to_json(students: List[Student], path: str) -> None:
    data = [student.to_dict() for student in students]
    with open(path, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    print(f"–î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {path}")
def students_from_json(path: str) -> List[Student]:
    try:
        with open(path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        students = []
        for item in data:
            try:
                student = Student.from_dict(item)
                students.append(student)
            except ValueError as e:
                print(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å —Å—Ç—É–¥–µ–Ω—Ç–∞ –∏–∑ –∑–∞–ø–∏—Å–∏ {item}: {e}")
        print(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(students)} —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –∏–∑ {path}")
        return students   
    except FileNotFoundError:
        print(f"–§–∞–π–ª {path} –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return []
    except json.JSONDecodeError as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ JSON —Ñ–∞–π–ª–∞: {e}")
        return []
if __name__ == "__main__": 
    students = [
        Student("–ò–≤–∞–Ω–æ–≤ –ò–≤–∞–Ω –ò–≤–∞–Ω–æ–≤–∏—á", "2007-02-19", "–ë–ò–í–¢-25-1", 3.5),
        Student("–ü–µ—Ç—Ä–æ–≤ –ü–µ—Ç—Ä –ü–µ—Ç—Ä–æ–≤–∏—á", "2006-12-12", "–ë–ò–í–¢-25-2", 4.5),
        Student("–°–µ–º—ë–Ω–æ–≤ –°–µ–º—ë–Ω –°–µ–º—ë–Ω–æ–≤–∏—á", "2007-03-10", "–ë–ò–í–¢-25-3", 4.9)
    ]
    students_to_json(students, "data/students_output.json")
    loaded_students = students_from_json("data/students_input.json")
    for student in loaded_students:
        print(student)
    
```
![02](./images/lab08/seriallize.png)
![03](./images/lab08/input.png)
![04](./images/lab08/output.png)

